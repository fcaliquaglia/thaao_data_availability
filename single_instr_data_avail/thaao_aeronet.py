#!/usr/local/bin/python3
# -*- coding: utf-8 -*-
# -------------------------------------------------------------------------------
#
"""
OK
https://github.com/NASAARSET/GEMS_AQ
https://colab.research.google.com/drive/13V4WAnA6dhQR1o2pHXZA0Wm2-H5Xk498
"""

# =============================================================
# CREATED:
# AFFILIATION: INGV
# AUTHORS: Filippo Cali' Quaglia
# =============================================================
#
# -------------------------------------------------------------------------------
__author__ = "Filippo Cali' Quaglia"
__credits__ = ["??????"]
__license__ = "GPL"
__version__ = "1.1"
__email__ = "filippo.caliquaglia@ingv.it"
__status__ = "Research"
__lastupdate__ = "February 2025"

# -*- coding: utf-8 -*-
"""read_aeronet_time_series.ipynb

Automatically generated by Colab. Modified by Filippo CalÃ¬ Quaglia Oct 2024

Original file is located at
    https://colab.research.google.com/drive/13V4WAnA6dhQR1o2pHXZA0Wm2-H5Xk498

- **Module:** read_aeronet_time_series.ipynb
- **Authors:** Petar Grigorov and Pawan Gupta
- **Organization:** NASA AERONET (https://aeronet.gsfc.nasa.gov/)
- **Date:** 07/03/2023
- **Last Revision:** 07/29/2024
- **Purpose:** Time-series analysis of AERONET sites AOD levels
- **Disclaimer:** The code is for demonstration purposes only. Users are responsible to check for accuracy and revise to fit their objective.
- **Contact:** Report any concern or question related to the code to pawan.gupta@nasa.gov or petar.t.grigorov@nasa.gov
- **Readme:** https://github.com/pawanpgupta/AERONET/blob/Python/README/Read_AERONET_TimeSeries

**Required packages installation and importing**
"""

"""**Setup input parameters such as date, data level, averaging type, AOD range for mapping, AOD/Angstrom exponent, and geographical limits**"""


def update_data_avail(instr):
    import datetime  # for time data manipulation
    import os

    import numpy as np  # for array manipulation
    import requests  # useful for sending HTTP requests
    from bs4 import BeautifulSoup  # reads data from website (web scraping)

    import pandas as pd
    import single_instr_data_avail.sida_tools as sida_tls

    import settings as ts

    date_list = pd.date_range(
            ts.instr_metadata[instr]['start_instr'], ts.instr_metadata[instr]['end_instr'], freq='D').tolist()
    folder = os.path.join(ts.basefolder, "thaao_" + instr)
    site = 'Thule'  # Please make sure site name is spelled properly
    dt_initial = ts.instr_metadata[instr]['start_instr'].strftime('%Y%m%d')  # starting date YYYYMMDD format
    dt_final = ts.instr_metadata[instr]['end_instr'].strftime('%Y%m%d')  # final date YYYYMMDD format
    level = 1.5  # AERONET data level
    average_type = 1  # daily (1), monthly (2)
    feature_choice = 1  # Enter '1' if you are specifying an AOD wavelength or '2' if you are specifying an Angstrom exponent
    wavelength = 500  # Available choices: 1640, 1020, 870, 865, 779, 675, 667, 620, 560, 555, 551, 532, 531, 510, 500, 490, 443, 440, 412, 400, 380, 340
    Angstrom_exp = '440-675'  # Available choices: '440-870','380-500','440-675','500-870','340-440','440-675(Polar)'

    """**Get desired AERONET data using web services, then scraping data from website**"""

    yr_initial = dt_initial[:4]  # initial year
    mon_initial = dt_initial[4:6]  # initial month
    day_initial = dt_initial[6:]  # initial day

    yr_final = dt_final[:4]  # final year
    mon_final = dt_final[4:6]  # final month
    day_final = dt_final[6:]  # final day

    if level == 1 or level == 1.0:
        level = 10
    elif level == 1.5:
        level = 15
    elif level == 2 or level == 2.0:
        level = 20
    else:
        print("\nIncorrect input for data level type. Defaulting to level 1.5...")
        level = 15

    if level == 20 and int(
            yr_initial) == datetime.date.today().year:  # if user wants level 2 data for the current year, program alerts that data may not be available
        level = 15  # defaults to level 1.5 data
        print("\nThere is no level 2 data available for the current year. Defaulting to level 1.5 data...")

    url = 'https://aeronet.gsfc.nasa.gov/cgi-bin/print_web_data_v3?site=' + site + '&year=' + yr_initial + '&month=' + mon_initial + '&day=' + day_initial + '&year2=' + yr_final + '&month2=' + mon_final + '&day2=' + day_final + '&AOD' + str(
            level) + '=1&AVG=20'
    soup = BeautifulSoup(requests.get(url).text, features="html.parser")  # web services contents are read here from URL

    """**Writes soup data to text file, assigns contents to Pandas dataframe, prepares data for plotting**"""
    with open(
            os.path.join(ts.basefolder, 'thaao_aeronet', 'temp.csv'),
            "w") as oFile:  # writes the data scraped from "beautiful soup" to a text file on your local Google drive
        oFile.write(str(soup.text))
        oFile.close()

    aeronet = pd.read_csv(
            os.path.join(ts.basefolder, 'thaao_aeronet', 'temp.csv'),
            skiprows=6)  # loads the csv data into a Pandas dataframe

    if len(aeronet) > 0:
        aeronet = aeronet.replace(
            -999.0, np.nan)  # replaces all -999.0 vakyes with NaN; helps with accurate data aggregation
        aeronet[['Day', 'Month', 'Year']] = aeronet['Date(dd:mm:yyyy)'].str.split(
                ':', expand=True)  # splits the date column and then joins it back together using "-" instead of ":"
        aeronet['Date'] = aeronet[['Year', 'Month', 'Day']].apply(
                lambda x: '-'.join(x.values.astype(str)),
                axis="columns")  # because datetime format in python does not recognize colons
        aeronet['Date'] = pd.to_datetime(aeronet['Date'])  # converts the new date column to datetime format
    else:
        print("No data to parse. Please retry with different parameters.")

    aeronet.set_index('Date', inplace=True)
    aeronet = aeronet[['AOD_440nm', 'AOD_1640nm', 'AOD_1020nm', 'AOD_870nm', 'AOD_865nm', 'AOD_779nm',
       'AOD_675nm', 'AOD_667nm', 'AOD_620nm', 'AOD_560nm', 'AOD_555nm',
       'AOD_551nm', 'AOD_532nm', 'AOD_531nm', 'AOD_510nm', 'AOD_500nm',
       'AOD_490nm', 'AOD_443nm', 'AOD_412nm', 'AOD_400nm',
       'AOD_380nm', 'AOD_340nm', 'Precipitable_Water(cm)', 'AOD_681nm',
       'AOD_709nm', 'AOD_Empty','440-870_Angstrom_Exponent', '380-500_Angstrom_Exponent',
       '440-675_Angstrom_Exponent', '500-870_Angstrom_Exponent',
       '340-440_Angstrom_Exponent', '440-675_Angstrom_Exponent[Polar]',
       'N[AOD_1640nm]', 'N[AOD_1020nm]', 'N[AOD_870nm]', 'N[AOD_865nm]',
       'N[AOD_779nm]', 'N[AOD_675nm]', 'N[AOD_667nm]', 'N[AOD_620nm]',
       'N[AOD_560nm]', 'N[AOD_555nm]', 'N[AOD_551nm]', 'N[AOD_532nm]',
       'N[AOD_531nm]', 'N[AOD_510nm]', 'N[AOD_500nm]', 'N[AOD_490nm]',
       'N[AOD_443nm]', 'N[AOD_440nm]', 'N[AOD_412nm]', 'N[AOD_400nm]',
       'N[AOD_380nm]', 'N[AOD_340nm]', 'N[Precipitable_Water(cm)]',
       'N[AOD_681nm]', 'N[AOD_709nm]',
       'N[440-870_Angstrom_Exponent]', 'N[380-500_Angstrom_Exponent]',
       'N[440-675_Angstrom_Exponent]', 'N[500-870_Angstrom_Exponent]',
       'N[340-440_Angstrom_Exponent]', 'N[440-675_Angstrom_Exponent[Polar]]',
       'Data_Quality_Level', 'AERONET_Instrument_Number',
       'Site_Latitude(Degrees)', 'Site_Longitude(Degrees)',
       'Site_Elevation(m)']]

    sida_tls.save_csv(instr, aeronet)
